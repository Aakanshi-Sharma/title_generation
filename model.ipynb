{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff39fbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Dense , LSTM, Dropout, Embedding\n",
    "from keras. models import Sequential\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03d9993a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words=stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2a2f02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bef2ae6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titles</th>\n",
       "      <th>summaries</th>\n",
       "      <th>terms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Survey on Semantic Stereo Matching / Semantic ...</td>\n",
       "      <td>Stereo matching is one of the widely used tech...</td>\n",
       "      <td>['cs.CV', 'cs.LG']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FUTURE-AI: Guiding Principles and Consensus Re...</td>\n",
       "      <td>The recent advancements in artificial intellig...</td>\n",
       "      <td>['cs.CV', 'cs.AI', 'cs.LG']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Enforcing Mutual Consistency of Hard Regions f...</td>\n",
       "      <td>In this paper, we proposed a novel mutual cons...</td>\n",
       "      <td>['cs.CV', 'cs.AI']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Parameter Decoupling Strategy for Semi-supervi...</td>\n",
       "      <td>Consistency training has proven to be an advan...</td>\n",
       "      <td>['cs.CV']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Background-Foreground Segmentation for Interio...</td>\n",
       "      <td>To ensure safety in automated driving, the cor...</td>\n",
       "      <td>['cs.CV', 'cs.LG']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              titles  \\\n",
       "0  Survey on Semantic Stereo Matching / Semantic ...   \n",
       "1  FUTURE-AI: Guiding Principles and Consensus Re...   \n",
       "2  Enforcing Mutual Consistency of Hard Regions f...   \n",
       "3  Parameter Decoupling Strategy for Semi-supervi...   \n",
       "4  Background-Foreground Segmentation for Interio...   \n",
       "\n",
       "                                           summaries  \\\n",
       "0  Stereo matching is one of the widely used tech...   \n",
       "1  The recent advancements in artificial intellig...   \n",
       "2  In this paper, we proposed a novel mutual cons...   \n",
       "3  Consistency training has proven to be an advan...   \n",
       "4  To ensure safety in automated driving, the cor...   \n",
       "\n",
       "                         terms  \n",
       "0           ['cs.CV', 'cs.LG']  \n",
       "1  ['cs.CV', 'cs.AI', 'cs.LG']  \n",
       "2           ['cs.CV', 'cs.AI']  \n",
       "3                    ['cs.CV']  \n",
       "4           ['cs.CV', 'cs.LG']  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80e07676",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"terms\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b922b10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stereo',\n",
       " 'matching',\n",
       " 'one',\n",
       " 'widely',\n",
       " 'used',\n",
       " 'techniques',\n",
       " 'inferring',\n",
       " 'depth',\n",
       " 'fromstereo',\n",
       " 'images',\n",
       " 'owing',\n",
       " 'robustness',\n",
       " 'speed',\n",
       " 'become',\n",
       " 'one',\n",
       " 'majortopics',\n",
       " 'research',\n",
       " 'since',\n",
       " 'finds',\n",
       " 'applications',\n",
       " 'autonomous',\n",
       " 'drivingrobotic',\n",
       " 'navigation',\n",
       " '3d',\n",
       " 'reconstruction',\n",
       " 'many',\n",
       " 'fields',\n",
       " 'finding',\n",
       " 'pixelcorrespondences',\n",
       " 'nontextured',\n",
       " 'occluded',\n",
       " 'reflective',\n",
       " 'areas',\n",
       " 'majorchallenge',\n",
       " 'stereo',\n",
       " 'matching',\n",
       " 'recent',\n",
       " 'developments',\n",
       " 'shown',\n",
       " 'semantic',\n",
       " 'cuesfrom',\n",
       " 'image',\n",
       " 'segmentation',\n",
       " 'used',\n",
       " 'improve',\n",
       " 'results',\n",
       " 'stereo',\n",
       " 'matchingmany',\n",
       " 'deep',\n",
       " 'neural',\n",
       " 'network',\n",
       " 'architectures',\n",
       " 'proposed',\n",
       " 'leverage',\n",
       " 'theadvantages',\n",
       " 'semantic',\n",
       " 'segmentation',\n",
       " 'stereo',\n",
       " 'matching',\n",
       " 'paper',\n",
       " 'aims',\n",
       " 'givea',\n",
       " 'comparison',\n",
       " 'among',\n",
       " 'state',\n",
       " 'art',\n",
       " 'networks',\n",
       " 'terms',\n",
       " 'accuracy',\n",
       " 'interms',\n",
       " 'speed',\n",
       " 'higher',\n",
       " 'importance',\n",
       " 'realtime',\n",
       " 'applications']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.summaries[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de36e8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_text(text):\n",
    "    lists=[]\n",
    "    text=text.lower()\n",
    "    text=text.replace('\\n', '')\n",
    "    text=text.strip().split(\" \")\n",
    "    for i in text:\n",
    "        if i not in stop_words:\n",
    "            lists.append(i)\n",
    "    returned_lists=[]\n",
    "    for i in lists:\n",
    "        arr=[]\n",
    "        for j in i:\n",
    "            if j not in string.punctuation:\n",
    "                arr.append(j)\n",
    "        \n",
    "        returned_lists.append(''.join(arr))\n",
    "    return returned_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e6588af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stereo',\n",
       " 'matching',\n",
       " 'one',\n",
       " 'widely',\n",
       " 'used',\n",
       " 'techniques',\n",
       " 'inferring',\n",
       " 'depth',\n",
       " 'fromstereo',\n",
       " 'images',\n",
       " 'owing',\n",
       " 'robustness',\n",
       " 'speed',\n",
       " 'become',\n",
       " 'one',\n",
       " 'majortopics',\n",
       " 'research',\n",
       " 'since',\n",
       " 'finds',\n",
       " 'applications',\n",
       " 'autonomous',\n",
       " 'drivingrobotic',\n",
       " 'navigation',\n",
       " '3d',\n",
       " 'reconstruction',\n",
       " 'many',\n",
       " 'fields',\n",
       " 'finding',\n",
       " 'pixelcorrespondences',\n",
       " 'nontextured',\n",
       " 'occluded',\n",
       " 'reflective',\n",
       " 'areas',\n",
       " 'majorchallenge',\n",
       " 'stereo',\n",
       " 'matching',\n",
       " 'recent',\n",
       " 'developments',\n",
       " 'shown',\n",
       " 'semantic',\n",
       " 'cuesfrom',\n",
       " 'image',\n",
       " 'segmentation',\n",
       " 'used',\n",
       " 'improve',\n",
       " 'results',\n",
       " 'stereo',\n",
       " 'matchingmany',\n",
       " 'deep',\n",
       " 'neural',\n",
       " 'network',\n",
       " 'architectures',\n",
       " 'proposed',\n",
       " 'leverage',\n",
       " 'theadvantages',\n",
       " 'semantic',\n",
       " 'segmentation',\n",
       " 'stereo',\n",
       " 'matching',\n",
       " 'paper',\n",
       " 'aims',\n",
       " 'givea',\n",
       " 'comparison',\n",
       " 'among',\n",
       " 'state',\n",
       " 'art',\n",
       " 'networks',\n",
       " 'terms',\n",
       " 'accuracy',\n",
       " 'interms',\n",
       " 'speed',\n",
       " 'higher',\n",
       " 'importance',\n",
       " 'realtime',\n",
       " 'applications']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing_text('Stereo matching is one of the widely used techniques for inferring depth from\\nstereo images owing to its robustness and speed. It has become one of the major\\ntopics of research since it finds its applications in autonomous driving,\\nrobotic navigation, 3D reconstruction, and many other fields. Finding pixel\\ncorrespondences in non-textured, occluded and reflective areas is the major\\nchallenge in stereo matching. Recent developments have shown that semantic cues\\nfrom image segmentation can be used to improve the results of stereo matching.\\nMany deep neural network architectures have been proposed to leverage the\\nadvantages of semantic segmentation in stereo matching. This paper aims to give\\na comparison among the state of art networks both in terms of accuracy and in\\nterms of speed which are of higher importance in real-time applications.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "162feecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['summaries']=df['summaries'].apply(preprocessing_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "834e7ba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titles</th>\n",
       "      <th>summaries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Survey on Semantic Stereo Matching / Semantic ...</td>\n",
       "      <td>[stereo, matching, one, widely, used, techniqu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FUTURE-AI: Guiding Principles and Consensus Re...</td>\n",
       "      <td>[recent, advancements, artificial, intelligenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Enforcing Mutual Consistency of Hard Regions f...</td>\n",
       "      <td>[paper, proposed, novel, mutual, consistency, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Parameter Decoupling Strategy for Semi-supervi...</td>\n",
       "      <td>[consistency, training, proven, advanced, semi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Background-Foreground Segmentation for Interio...</td>\n",
       "      <td>[ensure, safety, automated, driving, correct, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              titles  \\\n",
       "0  Survey on Semantic Stereo Matching / Semantic ...   \n",
       "1  FUTURE-AI: Guiding Principles and Consensus Re...   \n",
       "2  Enforcing Mutual Consistency of Hard Regions f...   \n",
       "3  Parameter Decoupling Strategy for Semi-supervi...   \n",
       "4  Background-Foreground Segmentation for Interio...   \n",
       "\n",
       "                                           summaries  \n",
       "0  [stereo, matching, one, widely, used, techniqu...  \n",
       "1  [recent, advancements, artificial, intelligenc...  \n",
       "2  [paper, proposed, novel, mutual, consistency, ...  \n",
       "3  [consistency, training, proven, advanced, semi...  \n",
       "4  [ensure, safety, automated, driving, correct, ...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "012e26c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1500b81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(df[\"summaries\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e567219e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning': 1,\n",
       " 'data': 2,\n",
       " 'model': 3,\n",
       " 'image': 4,\n",
       " 'methods': 5,\n",
       " 'network': 6,\n",
       " 'method': 7,\n",
       " 'propose': 8,\n",
       " 'models': 9,\n",
       " 'performance': 10,\n",
       " 'images': 11,\n",
       " 'proposed': 12,\n",
       " 'deep': 13,\n",
       " 'paper': 14,\n",
       " 'networks': 15,\n",
       " 'using': 16,\n",
       " 'results': 17,\n",
       " 'show': 18,\n",
       " 'neural': 19,\n",
       " 'training': 20,\n",
       " 'based': 21,\n",
       " 'approach': 22,\n",
       " 'graph': 23,\n",
       " 'tasks': 24,\n",
       " 'detection': 25,\n",
       " 'features': 26,\n",
       " 'problem': 27,\n",
       " 'information': 28,\n",
       " 'object': 29,\n",
       " 'datasets': 30,\n",
       " 'two': 31,\n",
       " 'different': 32,\n",
       " 'also': 33,\n",
       " 'new': 34,\n",
       " 'novel': 35,\n",
       " 'segmentation': 36,\n",
       " 'dataset': 37,\n",
       " 'however': 38,\n",
       " 'time': 39,\n",
       " 'task': 40,\n",
       " 'attention': 41,\n",
       " 'work': 42,\n",
       " 'used': 43,\n",
       " 'framework': 44,\n",
       " '3d': 45,\n",
       " 'stateoftheart': 46,\n",
       " 'experiments': 47,\n",
       " 'feature': 48,\n",
       " 'demonstrate': 49,\n",
       " 'algorithm': 50,\n",
       " 'use': 51,\n",
       " 'classification': 52,\n",
       " 'existing': 53,\n",
       " 'representation': 54,\n",
       " 'accuracy': 55,\n",
       " 'one': 56,\n",
       " 'first': 57,\n",
       " 'algorithms': 58,\n",
       " 'present': 59,\n",
       " 'learn': 60,\n",
       " 'point': 61,\n",
       " 'adversarial': 62,\n",
       " 'approaches': 63,\n",
       " 'space': 64,\n",
       " '': 65,\n",
       " 'visual': 66,\n",
       " 'large': 67,\n",
       " 'set': 68,\n",
       " 'input': 69,\n",
       " 'well': 70,\n",
       " 'many': 71,\n",
       " 'video': 72,\n",
       " 'recent': 73,\n",
       " 'convolutional': 74,\n",
       " 'prediction': 75,\n",
       " 'domain': 76,\n",
       " 'objects': 77,\n",
       " 'representations': 78,\n",
       " 'loss': 79,\n",
       " 'trained': 80,\n",
       " 'generative': 81,\n",
       " 'available': 82,\n",
       " 'applications': 83,\n",
       " 'reinforcement': 84,\n",
       " 'better': 85,\n",
       " 'analysis': 86,\n",
       " 'architecture': 87,\n",
       " 'semantic': 88,\n",
       " 'process': 89,\n",
       " 'multiple': 90,\n",
       " 'compared': 91,\n",
       " 'number': 92,\n",
       " 'due': 93,\n",
       " 'introduce': 94,\n",
       " 'knowledge': 95,\n",
       " 'provide': 96,\n",
       " 'recognition': 97,\n",
       " 'problems': 98,\n",
       " 'function': 99,\n",
       " 'without': 100,\n",
       " 'structure': 101,\n",
       " 'machine': 102,\n",
       " 'improve': 103,\n",
       " 'high': 104,\n",
       " 'study': 105,\n",
       " 'challenging': 106,\n",
       " 'human': 107,\n",
       " 'depth': 108,\n",
       " 'local': 109,\n",
       " 'transfer': 110,\n",
       " 'several': 111,\n",
       " 'vision': 112,\n",
       " 'various': 113,\n",
       " 'series': 114,\n",
       " 'estimation': 115,\n",
       " 'target': 116,\n",
       " 'techniques': 117,\n",
       " 'given': 118,\n",
       " 'design': 119,\n",
       " 'outperforms': 120,\n",
       " 'achieve': 121,\n",
       " 'system': 122,\n",
       " 'policy': 123,\n",
       " 'learned': 124,\n",
       " 'single': 125,\n",
       " 'real': 126,\n",
       " 'samples': 127,\n",
       " 'address': 128,\n",
       " 'three': 129,\n",
       " 'achieves': 130,\n",
       " 'graphs': 131,\n",
       " 'research': 132,\n",
       " 'experimental': 133,\n",
       " 'module': 134,\n",
       " 'rl': 135,\n",
       " 'efficient': 136,\n",
       " 'systems': 137,\n",
       " 'unsupervised': 138,\n",
       " 'code': 139,\n",
       " 'extensive': 140,\n",
       " 'distribution': 141,\n",
       " 'temporal': 142,\n",
       " 'important': 143,\n",
       " 'scene': 144,\n",
       " 'previous': 145,\n",
       " 'benchmark': 146,\n",
       " 'quality': 147,\n",
       " 'eg': 148,\n",
       " 'generate': 149,\n",
       " 'often': 150,\n",
       " 'spatial': 151,\n",
       " 'generation': 152,\n",
       " 'effective': 153,\n",
       " 'complex': 154,\n",
       " 'including': 155,\n",
       " 'optimization': 156,\n",
       " 'latent': 157,\n",
       " 'natural': 158,\n",
       " 'recently': 159,\n",
       " 'state': 160,\n",
       " 'across': 161,\n",
       " 'realworld': 162,\n",
       " 'parameters': 163,\n",
       " 'simple': 164,\n",
       " 'train': 165,\n",
       " 'map': 166,\n",
       " 'effectiveness': 167,\n",
       " 'applied': 168,\n",
       " 'specifically': 169,\n",
       " 'significantly': 170,\n",
       " 'may': 171,\n",
       " 'via': 172,\n",
       " 'evaluate': 173,\n",
       " 'language': 174,\n",
       " 'global': 175,\n",
       " 'generated': 176,\n",
       " 'robust': 177,\n",
       " 'thus': 178,\n",
       " 'supervised': 179,\n",
       " 'inference': 180,\n",
       " 'class': 181,\n",
       " 'mechanism': 182,\n",
       " 'even': 183,\n",
       " 'order': 184,\n",
       " 'current': 185,\n",
       " 'able': 186,\n",
       " 'computer': 187,\n",
       " 'cnn': 188,\n",
       " 'ie': 189,\n",
       " 'color': 190,\n",
       " 'face': 191,\n",
       " 'finally': 192,\n",
       " 'labels': 193,\n",
       " 'terms': 194,\n",
       " 'significant': 195,\n",
       " 'maps': 196,\n",
       " 'small': 197,\n",
       " 'layers': 198,\n",
       " 'prior': 199,\n",
       " 'evaluation': 200,\n",
       " 'perform': 201,\n",
       " 'source': 202,\n",
       " 'context': 203,\n",
       " 'architectures': 204,\n",
       " 'test': 205,\n",
       " 'node': 206,\n",
       " 'domains': 207,\n",
       " 'accurate': 208,\n",
       " 'processing': 209,\n",
       " 'flow': 210,\n",
       " 'standard': 211,\n",
       " 'decision': 212,\n",
       " 'gans': 213,\n",
       " 'synthetic': 214,\n",
       " 'field': 215,\n",
       " 'transformer': 216,\n",
       " 'regions': 217,\n",
       " 'cloud': 218,\n",
       " 'modeling': 219,\n",
       " 'key': 220,\n",
       " 'best': 221,\n",
       " 'find': 222,\n",
       " 'pose': 223,\n",
       " 'action': 224,\n",
       " 'allows': 225,\n",
       " 'shown': 226,\n",
       " 'focus': 227,\n",
       " 'gan': 228,\n",
       " 'layer': 229,\n",
       " 'particular': 230,\n",
       " 'search': 231,\n",
       " 'among': 232,\n",
       " 'limited': 233,\n",
       " 'works': 234,\n",
       " 'achieved': 235,\n",
       " 'general': 236,\n",
       " 'medical': 237,\n",
       " 'motion': 238,\n",
       " 'way': 239,\n",
       " 'control': 240,\n",
       " 'challenge': 241,\n",
       " 'moreover': 242,\n",
       " 'computational': 243,\n",
       " 'embedding': 244,\n",
       " 'clustering': 245,\n",
       " 'capture': 246,\n",
       " '1': 247,\n",
       " 'ability': 248,\n",
       " 'still': 249,\n",
       " 'cost': 250,\n",
       " 'within': 251,\n",
       " 'make': 252,\n",
       " 'functions': 253,\n",
       " 'addition': 254,\n",
       " 'learns': 255,\n",
       " 'provides': 256,\n",
       " 'called': 257,\n",
       " 'furthermore': 258,\n",
       " 'efficiency': 259,\n",
       " 'agents': 260,\n",
       " 'points': 261,\n",
       " 'gradient': 262,\n",
       " 'optimal': 263,\n",
       " 'dynamic': 264,\n",
       " 'technique': 265,\n",
       " 'shape': 266,\n",
       " 'agent': 267,\n",
       " 'similar': 268,\n",
       " 'properties': 269,\n",
       " 'linear': 270,\n",
       " '2': 271,\n",
       " 'text': 272,\n",
       " 'directly': 273,\n",
       " 'memory': 274,\n",
       " 'strategy': 275,\n",
       " 'sample': 276,\n",
       " 'sparse': 277,\n",
       " 'complexity': 278,\n",
       " 'videos': 279,\n",
       " 'generalization': 280,\n",
       " 'develop': 281,\n",
       " 'nodes': 282,\n",
       " 'endtoend': 283,\n",
       " 'challenges': 284,\n",
       " 'environment': 285,\n",
       " 'understanding': 286,\n",
       " 'uses': 287,\n",
       " 'result': 288,\n",
       " 'random': 289,\n",
       " 'classes': 290,\n",
       " 'solution': 291,\n",
       " 'setting': 292,\n",
       " 'noise': 293,\n",
       " 'size': 294,\n",
       " 'much': 295,\n",
       " 'ofthe': 296,\n",
       " 'need': 297,\n",
       " 'robustness': 298,\n",
       " 'error': 299,\n",
       " 'obtain': 300,\n",
       " 'fully': 301,\n",
       " 'designed': 302,\n",
       " '2d': 303,\n",
       " 'second': 304,\n",
       " 'output': 305,\n",
       " 'benchmarks': 306,\n",
       " 'common': 307,\n",
       " 'range': 308,\n",
       " 'improves': 309,\n",
       " 'level': 310,\n",
       " 'studies': 311,\n",
       " 'popular': 312,\n",
       " 'since': 313,\n",
       " 'clouds': 314,\n",
       " 'sequence': 315,\n",
       " 'fusion': 316,\n",
       " 'success': 317,\n",
       " 'require': 318,\n",
       " 'original': 319,\n",
       " 'frames': 320,\n",
       " 'future': 321,\n",
       " 'specific': 322,\n",
       " 'sets': 323,\n",
       " 'solve': 324,\n",
       " 'scale': 325,\n",
       " 'predict': 326,\n",
       " 'potential': 327,\n",
       " 'like': 328,\n",
       " 'years': 329,\n",
       " 'cnns': 330,\n",
       " 'baseline': 331,\n",
       " 'step': 332,\n",
       " 'predictions': 333,\n",
       " 'low': 334,\n",
       " 'wepropose': 335,\n",
       " 'requires': 336,\n",
       " 'application': 337,\n",
       " 'examples': 338,\n",
       " 'effectively': 339,\n",
       " 'value': 340,\n",
       " 'labeled': 341,\n",
       " 'label': 342,\n",
       " 'camera': 343,\n",
       " 'consider': 344,\n",
       " 'improvement': 345,\n",
       " 'structures': 346,\n",
       " 'obtained': 347,\n",
       " 'improved': 348,\n",
       " 'objective': 349,\n",
       " 'case': 350,\n",
       " 'us': 351,\n",
       " 'regression': 352,\n",
       " 'yet': 353,\n",
       " 'traditional': 354,\n",
       " 'types': 355,\n",
       " 'instance': 356,\n",
       " 'aims': 357,\n",
       " 'especially': 358,\n",
       " 'widely': 359,\n",
       " 'apply': 360,\n",
       " 'reduce': 361,\n",
       " 'issue': 362,\n",
       " 'distance': 363,\n",
       " 'form': 364,\n",
       " 'reward': 365,\n",
       " 'sampling': 366,\n",
       " 'environments': 367,\n",
       " 'convolution': 368,\n",
       " 'largescale': 369,\n",
       " 'known': 370,\n",
       " 'therefore': 371,\n",
       " 'scenarios': 372,\n",
       " 'enables': 373,\n",
       " 'scheme': 374,\n",
       " 'reconstruction': 375,\n",
       " 'part': 376,\n",
       " 'highly': 377,\n",
       " 'manner': 378,\n",
       " 'promising': 379,\n",
       " 'possible': 380,\n",
       " 'matching': 381,\n",
       " 'patterns': 382,\n",
       " 'variety': 383,\n",
       " 'main': 384,\n",
       " 'similarity': 385,\n",
       " 'resolution': 386,\n",
       " 'instead': 387,\n",
       " 'pretrained': 388,\n",
       " 'art': 389,\n",
       " 'optical': 390,\n",
       " 'matrix': 391,\n",
       " 'end': 392,\n",
       " 'good': 393,\n",
       " 'extract': 394,\n",
       " 'online': 395,\n",
       " 'could': 396,\n",
       " 'difficult': 397,\n",
       " 'explore': 398,\n",
       " 'tracking': 399,\n",
       " 'higher': 400,\n",
       " 'shows': 401,\n",
       " 'settings': 402,\n",
       " 'interest': 403,\n",
       " 'view': 404,\n",
       " 'generator': 405,\n",
       " 'gnns': 406,\n",
       " 'scenes': 407,\n",
       " 'efficiently': 408,\n",
       " 'usually': 409,\n",
       " 'less': 410,\n",
       " 'making': 411,\n",
       " 'weights': 412,\n",
       " 'theproposed': 413,\n",
       " 'related': 414,\n",
       " 'rate': 415,\n",
       " 'metric': 416,\n",
       " 'made': 417,\n",
       " 'classifier': 418,\n",
       " 'lack': 419,\n",
       " 'selfsupervised': 420,\n",
       " 'dynamics': 421,\n",
       " 'joint': 422,\n",
       " 'competitive': 423,\n",
       " 'resulting': 424,\n",
       " 'theoretical': 425,\n",
       " 'region': 426,\n",
       " 'adaptation': 427,\n",
       " 'dense': 428,\n",
       " 'diverse': 429,\n",
       " 'leads': 430,\n",
       " 'superior': 431,\n",
       " 'conditions': 432,\n",
       " 'despite': 433,\n",
       " 'recurrent': 434,\n",
       " 'metrics': 435,\n",
       " 'evaluated': 436,\n",
       " 'generating': 437,\n",
       " 'wide': 438,\n",
       " 'makes': 439,\n",
       " 'transformation': 440,\n",
       " 'selection': 441,\n",
       " 'empirical': 442,\n",
       " 'useful': 443,\n",
       " 'components': 444,\n",
       " 'embeddings': 445,\n",
       " 'multimodal': 446,\n",
       " 'corresponding': 447,\n",
       " 'policies': 448,\n",
       " 'produce': 449,\n",
       " 'additional': 450,\n",
       " 'great': 451,\n",
       " 'distributions': 452,\n",
       " 'augmentation': 453,\n",
       " 'estimate': 454,\n",
       " 'power': 455,\n",
       " 'goal': 456,\n",
       " 'cases': 457,\n",
       " 'faster': 458,\n",
       " 'fast': 459,\n",
       " 'facial': 460,\n",
       " 'computation': 461,\n",
       " 'continuous': 462,\n",
       " 'constraints': 463,\n",
       " 'behavior': 464,\n",
       " 'conditional': 465,\n",
       " 'hierarchical': 466,\n",
       " 'vector': 467,\n",
       " 'strong': 468,\n",
       " 'attacks': 469,\n",
       " 'respectively': 470,\n",
       " 'solutions': 471,\n",
       " 'consists': 472,\n",
       " 'geometric': 473,\n",
       " 'kernel': 474,\n",
       " 'developed': 475,\n",
       " 'either': 476,\n",
       " 'speed': 477,\n",
       " 'compare': 478,\n",
       " 'practical': 479,\n",
       " 'improvements': 480,\n",
       " 'importance': 481,\n",
       " 'edge': 482,\n",
       " 'amount': 483,\n",
       " 'identify': 484,\n",
       " 'adaptive': 485,\n",
       " 'autonomous': 486,\n",
       " 'average': 487,\n",
       " 'world': 488,\n",
       " 'values': 489,\n",
       " 'user': 490,\n",
       " 'help': 491,\n",
       " 'inputs': 492,\n",
       " 'investigate': 493,\n",
       " 'interactions': 494,\n",
       " 'attributes': 495,\n",
       " 'uncertainty': 496,\n",
       " 'convergence': 497,\n",
       " 'thispaper': 498,\n",
       " 'jointly': 499,\n",
       " 'frame': 500,\n",
       " 'underlying': 501,\n",
       " 'forecasting': 502,\n",
       " 'detect': 503,\n",
       " 'localization': 504,\n",
       " 'parts': 505,\n",
       " 'contrast': 506,\n",
       " 'rely': 507,\n",
       " 'timeseries': 508,\n",
       " 'inthis': 509,\n",
       " 'towards': 510,\n",
       " 'actions': 511,\n",
       " 'example': 512,\n",
       " 'critical': 513,\n",
       " 'driving': 514,\n",
       " 'issues': 515,\n",
       " 'changes': 516,\n",
       " 'exploit': 517,\n",
       " 'presents': 518,\n",
       " 'hand': 519,\n",
       " 'four': 520,\n",
       " 'tackle': 521,\n",
       " 'performs': 522,\n",
       " 'increasing': 523,\n",
       " 'simultaneously': 524,\n",
       " 'demonstrated': 525,\n",
       " 'baselines': 526,\n",
       " 'person': 527,\n",
       " 'score': 528,\n",
       " 'although': 529,\n",
       " 'variables': 530,\n",
       " 'annotations': 531,\n",
       " 'traffic': 532,\n",
       " 'content': 533,\n",
       " 'introduced': 534,\n",
       " 'long': 535,\n",
       " 'inthe': 536,\n",
       " 'leverage': 537,\n",
       " 'exploration': 538,\n",
       " 'along': 539,\n",
       " 'unseen': 540,\n",
       " 'translation': 541,\n",
       " 'sequences': 542,\n",
       " 'individual': 543,\n",
       " 'proposes': 544,\n",
       " 'automatically': 545,\n",
       " 'supervision': 546,\n",
       " 'gap': 547,\n",
       " 'become': 548,\n",
       " 'build': 549,\n",
       " 'inspired': 550,\n",
       " 'powerful': 551,\n",
       " 'reasoning': 552,\n",
       " 'detectors': 553,\n",
       " 'area': 554,\n",
       " 'support': 555,\n",
       " 'measure': 556,\n",
       " 'realistic': 557,\n",
       " 'discriminative': 558,\n",
       " 'tree': 559,\n",
       " 'named': 560,\n",
       " 'validate': 561,\n",
       " 'pixels': 562,\n",
       " 'detector': 563,\n",
       " 'stochastic': 564,\n",
       " 'bias': 565,\n",
       " 'background': 566,\n",
       " 'regularization': 567,\n",
       " 'lower': 568,\n",
       " 'progress': 569,\n",
       " 'saliency': 570,\n",
       " 'typically': 571,\n",
       " 'mapping': 572,\n",
       " 'strategies': 573,\n",
       " 'question': 574,\n",
       " 'building': 575,\n",
       " 'idea': 576,\n",
       " 'improving': 577,\n",
       " 'analyze': 578,\n",
       " 'transform': 579,\n",
       " 'take': 580,\n",
       " 'conventional': 581,\n",
       " 'advances': 582,\n",
       " 'pairs': 583,\n",
       " 'style': 584,\n",
       " 'relevant': 585,\n",
       " 'extraction': 586,\n",
       " 'stage': 587,\n",
       " 'automatic': 588,\n",
       " 'instances': 589,\n",
       " 'variational': 590,\n",
       " 'signal': 591,\n",
       " 'compression': 592,\n",
       " 'imaging': 593,\n",
       " 'crucial': 594,\n",
       " 'structured': 595,\n",
       " 'observations': 596,\n",
       " 'aim': 597,\n",
       " 'selfattention': 598,\n",
       " 'public': 599,\n",
       " 'component': 600,\n",
       " 'consistency': 601,\n",
       " '3': 602,\n",
       " 'encoder': 603,\n",
       " 'unlabeled': 604,\n",
       " 'nonlinear': 605,\n",
       " 'observed': 606,\n",
       " 'literature': 607,\n",
       " 'fields': 608,\n",
       " 'semisupervised': 609,\n",
       " 'outperform': 610,\n",
       " 'increase': 611,\n",
       " 'signals': 612,\n",
       " 'appearance': 613,\n",
       " 'lead': 614,\n",
       " 'full': 615,\n",
       " 'comparison': 616,\n",
       " 'synthesis': 617,\n",
       " 'modules': 618,\n",
       " 'development': 619,\n",
       " 'realtime': 620,\n",
       " 'ground': 621,\n",
       " 'states': 622,\n",
       " 'transformations': 623,\n",
       " 'cannot': 624,\n",
       " 'effect': 625,\n",
       " 'final': 626,\n",
       " 'relationships': 627,\n",
       " 'role': 628,\n",
       " 'rgb': 629,\n",
       " 'imagenet': 630,\n",
       " 'factors': 631,\n",
       " 'found': 632,\n",
       " 'relations': 633,\n",
       " 'empirically': 634,\n",
       " 'bounding': 635,\n",
       " 'extracted': 636,\n",
       " 'capable': 637,\n",
       " 'then': 638,\n",
       " 'explicitly': 639,\n",
       " 'easily': 640,\n",
       " 'explain': 641,\n",
       " 'type': 642,\n",
       " 'pixel': 643,\n",
       " 'theory': 644,\n",
       " 'comparable': 645,\n",
       " 'applying': 646,\n",
       " 'handle': 647,\n",
       " 'users': 648,\n",
       " 'enhance': 649,\n",
       " 'probability': 650,\n",
       " 'publicly': 651,\n",
       " 'interaction': 652,\n",
       " 'procedure': 653,\n",
       " 'conduct': 654,\n",
       " 'statistical': 655,\n",
       " 'superresolution': 656,\n",
       " 'noisy': 657,\n",
       " 'retrieval': 658,\n",
       " 'contrastive': 659,\n",
       " 'essential': 660,\n",
       " 'conducted': 661,\n",
       " 'performed': 662,\n",
       " 'structural': 663,\n",
       " 'represent': 664,\n",
       " 'pipeline': 665,\n",
       " 'advantage': 666,\n",
       " 'mean': 667,\n",
       " 'solving': 668,\n",
       " 'attack': 669,\n",
       " 'approximation': 670,\n",
       " 'major': 671,\n",
       " 'gnn': 672,\n",
       " 'discriminator': 673,\n",
       " 'ones': 674,\n",
       " 'anomaly': 675,\n",
       " 'gaussian': 676,\n",
       " 'that': 677,\n",
       " 'consistent': 678,\n",
       " 'processes': 679,\n",
       " 'fundamental': 680,\n",
       " 'predicting': 681,\n",
       " 'views': 682,\n",
       " 'multiscale': 683,\n",
       " 'utilize': 684,\n",
       " 'achieving': 685,\n",
       " 'bayesian': 686,\n",
       " 'bound': 687,\n",
       " 'spaces': 688,\n",
       " 'interpretable': 689,\n",
       " 'downstream': 690,\n",
       " 'modalities': 691,\n",
       " 'practice': 692,\n",
       " 'required': 693,\n",
       " 'open': 694,\n",
       " 'alignment': 695,\n",
       " 'remains': 696,\n",
       " 'provided': 697,\n",
       " 'texture': 698,\n",
       " 'combination': 699,\n",
       " 'impact': 700,\n",
       " 'categories': 701,\n",
       " 'prove': 702,\n",
       " 'causal': 703,\n",
       " 'brain': 704,\n",
       " 'combined': 705,\n",
       " 'classifiers': 706,\n",
       " 'levels': 707,\n",
       " 'parameter': 708,\n",
       " 'details': 709,\n",
       " 'areas': 710,\n",
       " 'expensive': 711,\n",
       " 'quantitative': 712,\n",
       " 'limitations': 713,\n",
       " 'respect': 714,\n",
       " 'discrete': 715,\n",
       " 'namely': 716,\n",
       " 'transformers': 717,\n",
       " 'lidar': 718,\n",
       " 'nature': 719,\n",
       " 'query': 720,\n",
       " 'trees': 721,\n",
       " 'enable': 722,\n",
       " 'ensemble': 723,\n",
       " 'learningbased': 724,\n",
       " 'edges': 725,\n",
       " 'explanations': 726,\n",
       " 'hard': 727,\n",
       " 'overall': 728,\n",
       " 'certain': 729,\n",
       " 'dependencies': 730,\n",
       " 'scales': 731,\n",
       " 'box': 732,\n",
       " 'generalize': 733,\n",
       " 'predictive': 734,\n",
       " 'another': 735,\n",
       " 'construct': 736,\n",
       " 'testing': 737,\n",
       " 'past': 738,\n",
       " 'salient': 739,\n",
       " 'missing': 740,\n",
       " 'advantages': 741,\n",
       " 'relationship': 742,\n",
       " 'block': 743,\n",
       " 'annotated': 744,\n",
       " 'presented': 745,\n",
       " 'autoencoder': 746,\n",
       " 'characteristics': 747,\n",
       " 'geometry': 748,\n",
       " 'additionally': 749,\n",
       " 'pretraining': 750,\n",
       " 'steps': 751,\n",
       " 'providing': 752,\n",
       " 'change': 753,\n",
       " 'correlation': 754,\n",
       " 'ii': 755,\n",
       " 'comprehensive': 756,\n",
       " 'group': 757,\n",
       " 'community': 758,\n",
       " 'suitable': 759,\n",
       " 'leading': 760,\n",
       " 'allow': 761,\n",
       " 'encoding': 762,\n",
       " 'binary': 763,\n",
       " 'decoder': 764,\n",
       " 'operations': 765,\n",
       " 'considered': 766,\n",
       " 'combining': 767,\n",
       " 'fail': 768,\n",
       " 'extend': 769,\n",
       " 'energy': 770,\n",
       " 'fixed': 771,\n",
       " 'commonly': 772,\n",
       " 'spatiotemporal': 773,\n",
       " 'perspective': 774,\n",
       " 'neuralnetworks': 775,\n",
       " 'property': 776,\n",
       " 'tothe': 777,\n",
       " 'takes': 778,\n",
       " 'pooling': 779,\n",
       " 'sequential': 780,\n",
       " 'successfully': 781,\n",
       " 'etc': 782,\n",
       " 'leveraging': 783,\n",
       " 'spectral': 784,\n",
       " 'variations': 785,\n",
       " 'fashion': 786,\n",
       " 'suffer': 787,\n",
       " 'markov': 788,\n",
       " 'describe': 789,\n",
       " 'overcome': 790,\n",
       " 'light': 791,\n",
       " 'i': 792,\n",
       " 'showthat': 793,\n",
       " 'onthe': 794,\n",
       " 'formulation': 795,\n",
       " 'contextual': 796,\n",
       " 'kitti': 797,\n",
       " 'concept': 798,\n",
       " 'times': 799,\n",
       " 'sensor': 800,\n",
       " 'unified': 801,\n",
       " 'unlike': 802,\n",
       " 'according': 803,\n",
       " 'together': 804,\n",
       " 'mechanisms': 805,\n",
       " 'annotation': 806,\n",
       " 'generates': 807,\n",
       " 'probabilistic': 808,\n",
       " 'rich': 809,\n",
       " 'perception': 810,\n",
       " 'discuss': 811,\n",
       " 'shapes': 812,\n",
       " 'associated': 813,\n",
       " 'reduction': 814,\n",
       " 'dnns': 815,\n",
       " 'computing': 816,\n",
       " 'hence': 817,\n",
       " 'sensors': 818,\n",
       " 'mask': 819,\n",
       " 'capability': 820,\n",
       " 'clinical': 821,\n",
       " 'this': 822,\n",
       " 'interpretability': 823,\n",
       " 'alternative': 824,\n",
       " 'upon': 825,\n",
       " 'poses': 826,\n",
       " 'hidden': 827,\n",
       " 'whether': 828,\n",
       " 'combine': 829,\n",
       " 'derive': 830,\n",
       " 'implementation': 831,\n",
       " 'cameras': 832,\n",
       " 'active': 833,\n",
       " 'term': 834,\n",
       " 'estimates': 835,\n",
       " 'rather': 836,\n",
       " 'tool': 837,\n",
       " 'mainly': 838,\n",
       " 'artificial': 839,\n",
       " 'automated': 840,\n",
       " 'compute': 841,\n",
       " 'density': 842,\n",
       " 'monocular': 843,\n",
       " 'accurately': 844,\n",
       " 'classical': 845,\n",
       " 'understand': 846,\n",
       " 'truth': 847,\n",
       " 'modern': 848,\n",
       " 'raw': 849,\n",
       " 'unknown': 850,\n",
       " 'seen': 851,\n",
       " 'outputs': 852,\n",
       " 'considering': 853,\n",
       " 'employ': 854,\n",
       " 'humans': 855,\n",
       " 'detecting': 856,\n",
       " 'fewshot': 857,\n",
       " 'arbitrary': 858,\n",
       " 'finegrained': 859,\n",
       " 'vectors': 860,\n",
       " 'residual': 861,\n",
       " 'performing': 862,\n",
       " 'diversity': 863,\n",
       " 'devices': 864,\n",
       " 'particularly': 865,\n",
       " 'vehicle': 866,\n",
       " 'shared': 867,\n",
       " 'contains': 868,\n",
       " 'them': 869,\n",
       " 'relative': 870,\n",
       " 'concepts': 871,\n",
       " 'surface': 872,\n",
       " 'numerical': 873,\n",
       " 'thestateoftheart': 874,\n",
       " 'independent': 875,\n",
       " 'besides': 876,\n",
       " 'tested': 877,\n",
       " 'aggregation': 878,\n",
       " 'tools': 879,\n",
       " 'highdimensional': 880,\n",
       " 'benefits': 881,\n",
       " 'initial': 882,\n",
       " 'deeplearning': 883,\n",
       " 'paradigm': 884,\n",
       " 'patches': 885,\n",
       " 'whole': 886,\n",
       " 'superiority': 887,\n",
       " 'showing': 888,\n",
       " 'risk': 889,\n",
       " 'collected': 890,\n",
       " 'highresolution': 891,\n",
       " 'captioning': 892,\n",
       " 'highquality': 893,\n",
       " 'effects': 894,\n",
       " 'ai': 895,\n",
       " 'margin': 896,\n",
       " 'motivated': 897,\n",
       " 'far': 898,\n",
       " 'registration': 899,\n",
       " 'combines': 900,\n",
       " 'optimize': 901,\n",
       " 'would': 902,\n",
       " 'weight': 903,\n",
       " 'defined': 904,\n",
       " 'game': 905,\n",
       " 'variable': 906,\n",
       " 'approximate': 907,\n",
       " 'following': 908,\n",
       " 'sr': 909,\n",
       " 'boxes': 910,\n",
       " 'highlevel': 911,\n",
       " 'games': 912,\n",
       " 'studied': 913,\n",
       " 'al': 914,\n",
       " 'negative': 915,\n",
       " 'multiview': 916,\n",
       " 'finding': 917,\n",
       " 'variance': 918,\n",
       " 'researchers': 919,\n",
       " 'filter': 920,\n",
       " 'lstm': 921,\n",
       " 'attribute': 922,\n",
       " 'relation': 923,\n",
       " 'manifold': 924,\n",
       " 'estimating': 925,\n",
       " 'precision': 926,\n",
       " 'insights': 927,\n",
       " 'generally': 928,\n",
       " 'rewards': 929,\n",
       " 'observation': 930,\n",
       " 'reduces': 931,\n",
       " 'errors': 932,\n",
       " 'scores': 933,\n",
       " 'incorporate': 934,\n",
       " 'expression': 935,\n",
       " 'introduces': 936,\n",
       " 'sensing': 937,\n",
       " 'flexible': 938,\n",
       " 'faces': 939,\n",
       " 'deal': 940,\n",
       " 'aspects': 941,\n",
       " 'social': 942,\n",
       " 'successful': 943,\n",
       " 'multitask': 944,\n",
       " 'events': 945,\n",
       " 'captured': 946,\n",
       " 'adapt': 947,\n",
       " 'vehicles': 948,\n",
       " 'allowing': 949,\n",
       " 'distillation': 950,\n",
       " 'bounds': 951,\n",
       " 'operation': 952,\n",
       " 'phase': 953,\n",
       " 'neuralnetwork': 954,\n",
       " 'per': 955,\n",
       " 'every': 956,\n",
       " 'previously': 957,\n",
       " 'exploiting': 958,\n",
       " 'body': 959,\n",
       " 'pruning': 960,\n",
       " 'employed': 961,\n",
       " 'channel': 962,\n",
       " 'qualitative': 963,\n",
       " 'et': 964,\n",
       " 'measures': 965,\n",
       " 'encode': 966,\n",
       " 'next': 967,\n",
       " 'explicit': 968,\n",
       " 'larger': 969,\n",
       " 'filters': 970,\n",
       " 'suggest': 971,\n",
       " 'guide': 972,\n",
       " 'physical': 973,\n",
       " 'reid': 974,\n",
       " 'constraint': 975,\n",
       " 'create': 976,\n",
       " 'road': 977,\n",
       " 'factor': 978,\n",
       " 'benefit': 979,\n",
       " 'dnn': 980,\n",
       " 'auxiliary': 981,\n",
       " 'event': 982,\n",
       " 'account': 983,\n",
       " 'planning': 984,\n",
       " 'built': 985,\n",
       " 'finetuning': 986,\n",
       " 'predicted': 987,\n",
       " 'heterogeneous': 988,\n",
       " 'objectdetection': 989,\n",
       " 'attracted': 990,\n",
       " 'observe': 991,\n",
       " 'boundary': 992,\n",
       " 'molecular': 993,\n",
       " 'direction': 994,\n",
       " 'anovel': 995,\n",
       " 'labeling': 996,\n",
       " 'contribution': 997,\n",
       " 'location': 998,\n",
       " 'complete': 999,\n",
       " 'whose': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad580e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "l=len(tokenizer.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a09887b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
